# Robot Agent - Supervised Hierarchical Planning System

A LangGraph-based robot planning agent that decomposes natural language commands into executable robot tasks through a supervised, multi-stage planning pipeline with interactive feedback loops.

## ğŸ“‹ Overview

The robot agent uses a **supervised planning approach** that combines:
- **Intent Classification** - Determines request type (new task, modification, question, end)
- **Feasibility Checking** - Validates whether requests can be executed
- **Interactive Feedback** - Provides explanations when requests cannot be fulfilled
- **Question Answering** - Handles user queries about environment or capabilities
- **Hierarchical Decomposition** - Breaks down feasible tasks into goals and executable tasks

## ğŸ—ï¸ System Architecture

### Graph Structure

![Planning Graph](graph.png)

The system implements a **StateGraph** with the following nodes and conditional routing:

```
START â†’ user_input â†’ intent â†’ [Router: intent]
                                   â”œâ”€â†’ end (END)
                                   â”œâ”€â†’ accept â†’ supervisor â†’ [Router: supervisor]
                                   â”œâ”€â†’ accept_no_feedback â†’ feedback â†’ user_input
                                   â”œâ”€â†’ new â†’ supervisor                            â”‚
                                   â””â”€â†’ question â†’ question_answer â†’ user_input    â”‚
                                                                                   â”‚
supervisor router: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”œâ”€â†’ feasible â†’ goal_decomp â†’ task_decomp â†’ END
    â””â”€â†’ not_feasible â†’ feedback â†’ user_input
```

### Node Descriptions

| Node | Purpose | Output |
|------|---------|--------|
| **user_input** | Captures user query interactively | Adds query to state |
| **intent** | Classifies user's intention | `{intent, reason, needs_feedback}` |
| **supervisor** | Validates feasibility with robot capabilities | `{feasible, reason}` |
| **feedback** | Generates explanation for infeasible/unclear requests | `{feedback_message}` |
| **question_answer** | Answers environment/capability questions | `{question, answer}` |
| **goal_decomp** | Decomposes command into high-level subgoals | `{subgoals: [str]}` |
| **task_decomp** | Converts subgoals into executable task sequences | `{tasks: [dict]}` |

### Routing Logic

#### Intent Router
Routes based on classified user intention:
- `"end"` â†’ Terminate conversation (END)
- `"accept"` â†’ Accept modified request â†’ supervisor
- `"accept_no_feedback"` â†’ Accept with feedback â†’ feedback
- `"new"` â†’ New task request â†’ supervisor
- `"question"` â†’ User question â†’ question_answer

#### Supervisor Router
Routes based on feasibility check:
- `"feasible"` â†’ Proceed to planning â†’ goal_decomp
- `"not_feasible"` â†’ Provide feedback â†’ feedback

## ğŸ“ Project Structure

```
robot_agent/
â”œâ”€â”€ main.py                    # Entry point for CLI execution
â”œâ”€â”€ graph.png                  # System architecture diagram
â”œâ”€â”€ environment.yml            # Conda environment specification
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â”œâ”€â”€ enums.py          # Model name enumerations (GPT-4, GPT-5 variants)
â”‚   â”‚   â”œâ”€â”€ errors.py         # Custom exception hierarchy
â”‚   â”‚   â””â”€â”€ logger.py         # Centralized logging with rotation
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.py         # Pydantic configuration loader
â”‚   â”‚   â””â”€â”€ config.yaml       # Node settings, skills, task templates
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ planning_prompt.py    # Goal/task decomposition prompts
â”‚   â”‚   â””â”€â”€ process_prompt.py     # Intent/supervisor/feedback prompts
â”‚   â”œâ”€â”€ runner/
â”‚   â”‚   â”œâ”€â”€ state.py          # StateSchema and StateMaker
â”‚   â”‚   â”œâ”€â”€ graph.py          # LLM chain builders and graph constructor
â”‚   â”‚   â”œâ”€â”€ runner.py         # SupervisedPlanRunner orchestration
â”‚   â”‚   â””â”€â”€ text.py           # Formatters for objects/skills/groups
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ file.py           # File I/O utilities (json, yaml, pkl, csv)
â”‚   â”œâ”€â”€ rag/                  # (Placeholder for retrieval)
â”‚   â””â”€â”€ tools/                # (Placeholder for external tools)
â”œâ”€â”€ data/                      # Runtime data storage
â””â”€â”€ test_planning.ipynb        # Interactive testing notebook
```

## ğŸ”„ Data Flow

### State Schema
```python
StateSchema = {
    "user_queries": List[str],              # User input history
    "inputs": Dict[str, Any],               # Environment context (objects, skills, groups)
    "intent_result": Dict[str, Any],        # Intent classification output
    "supervisor_result": Dict[str, Any],    # Feasibility check output
    "feedback_result": Dict[str, Any],      # Generated feedback message
    "feedback_loop_count": int,             # Number of feedback iterations
    "subgoals": List[str],                  # High-level goal decomposition
    "tasks": List[Dict[str, Any]],          # Executable task sequences
    "question_answers": List[Dict[str, Any]] # Q&A history
}
```

### Execution Flow Example

**User Input:** *"Bring the apple to the table"*

1. **user_input** â†’ Captures: `"Bring the apple to the table"`
2. **intent** â†’ Classifies: `{intent: "new", reason: "User wants robot to perform new task", needs_feedback: false}`
3. **supervisor** â†’ Validates: `{feasible: true, reason: "Robot has GoToObject, PickObject, PlaceObject skills"}`
4. **goal_decomp** â†’ Decomposes: `{subgoals: ["Bring the apple to the table"]}`
5. **task_decomp** â†’ Plans:
   ```json
   {
     "tasks": [
       {"skill": "GoToObject", "target": "apple"},
       {"skill": "PickObject", "target": "apple"},
       {"skill": "GoToObject", "target": "table"},
       {"skill": "PlaceObject", "target": "table", "object": "apple"}
     ]
   }
   ```

## ğŸš€ Quick Start

### Installation

```bash
# Create conda environment
conda env create -f environment.yml
conda activate robot_agent

# Or use pip
pip install -r requirements.txt
```

### Configuration

Edit `src/config/config.yaml`:

```yaml
runner:
  intent_node:
    model_name: gpt41mini           # OpenAI model for intent classification
    prompt_cache_key: intent_node   # Cache key for prompt optimization
  supervisor_node:
    model_name: gpt41mini
    prompt_cache_key: supervisor_node
  # ... (other nodes)

skills:
  - name: robot1
    skills: ['GoToObject', 'OpenObject', 'CloseObject', 'PickObject', 'PlaceObject']

tasks:
  GoToObject:
    description: "Move to the specified object."
    template: "GoToObject <robot><object>"
  # ... (other task templates)
```

### Usage

```python
from src.config.config import load_config
from src.runner.state import StateMaker
from src.runner.runner import SupervisedPlanRunner

# Load configuration
config = load_config()

# Create state factory
state_maker = StateMaker(config, url="http://127.0.0.1:8800")

# Initialize runner
runner = SupervisedPlanRunner(config)

# Run planning pipeline
initial_state = state_maker.make(user_query="Bring me a cup")
final_state = runner.invoke(initial_state)

# Access results
print(final_state["subgoals"])
print(final_state["tasks"])
```

### CLI Execution

```bash
python main.py "Bring the apple to the table"
```

## ğŸ› ï¸ Key Components

### LLM Chain Architecture

Each node is built using `make_normal_node()`:

```python
make_normal_node(
    llm=create_llm(model_name, temperature, prompt_cache_key),
    prompt_text=PROMPT_TEMPLATE,
    make_inputs=input_formatter_function,
    parser_output=PydanticOutputModel,
    state_key="result_field",
    state_append=False,
    node_name="NODE_NAME"
)
```

**Features:**
- Automatic Pydantic output parsing
- Format instruction injection
- Token usage tracking
- Rate limit handling with exponential backoff
- Model name resolution and tagging

### Error Handling

Custom error hierarchy with structured context:

```python
class BaseServiceError(Exception):
    error_code: str
    status_code: int
    domain: str
    details: Dict[str, Any]
```

**Error Types:**
- `ConfigError` - Invalid configuration
- `LLMError` - API call failures
- `RateLimitExceededError` - Rate limit violations
- `GraphExecutionError` - Pipeline failures
- `ParsingError` - Output parsing issues

### Logging

Automatic file rotation with module-level loggers:

```python
from src.common.logger import get_logger

logger = get_logger(__name__, is_save=True)
logger.info("Processing started")
logger.error("Failed to parse output", exc_info=True)
```

## ğŸ”§ Advanced Features

### Prompt Caching

OpenAI prompt caching reduces costs for repeated calls:

```yaml
runner:
  intent_node:
    prompt_cache_key: intent_node  # Enables caching for this node
```

### LLM Instance Caching

Runner maintains a cache to avoid recreating models:

```python
cache_key = (model_name, temperature, prompt_cache_key, bind_tools)
llm = self._llm_cache.get(cache_key) or create_llm(...)
```

### Environment Integration

Fetches live environment data via HTTP:

```python
state_maker = StateMaker(config, url="http://127.0.0.1:8800")
inputs = state_maker.make_inputs()
# Returns: {object_text, skill_text, group_list_text}
```

## ğŸ“Š Monitoring

### Token Usage Tracking

Each LLM call records:
- `total_tokens` - Total tokens consumed
- `x-ratelimit-remaining-tokens` - Remaining quota
- `x-ratelimit-remaining-requests` - Remaining request count

### Callback Support

```python
runner = SupervisedPlanRunner(
    config,
    token_information_changed_callback=lambda info: print(info)
)
```

## ğŸ§ª Testing

```bash
# Interactive testing
jupyter notebook test_planning.ipynb

# Unit tests (if available)
pytest tests/
```

## ğŸ¯ Design Principles

1. **Separation of Concerns** - Intent, feasibility, and planning are distinct stages
2. **User-Centric** - Interactive feedback loop ensures clarity
3. **Flexibility** - YAML configuration for easy model/skill updates
4. **Robustness** - Comprehensive error handling and retry logic
5. **Observability** - Detailed logging and token tracking

## ğŸ“ Example Scenarios

### Scenario 1: Feasible Request
```
User: "Pick up the fork from the counter"
Intent: new â†’ Supervisor: feasible â†’ Goal Decomp â†’ Task Decomp â†’ END
```

### Scenario 2: Infeasible Request
```
User: "Fly to the ceiling"
Intent: new â†’ Supervisor: not_feasible â†’ Feedback: "Robot cannot fly..." â†’ User Input
```

### Scenario 3: Question
```
User: "What objects are on the table?"
Intent: question â†’ Question Answer: "bowl, fork, plate" â†’ User Input
```

### Scenario 4: Request Modification
```
User: "Actually, bring two apples"
Intent: accept â†’ Supervisor: feasible â†’ Goal Decomp â†’ ...
```

## ğŸ”® Future Enhancements

- [ ] Action-level planning with primitive motions
- [ ] RAG integration for knowledge retrieval
- [ ] Multi-robot coordination
- [ ] Visual grounding with object detection
- [ ] Execution monitoring and replanning
- [ ] Natural language plan explanations

## ğŸ“š Dependencies

| Library | Purpose |
|---------|---------|
| `langchain` | LLM orchestration framework |
| `langgraph` | Graph-based workflow management |
| `openai` | GPT model API access |
| `pydantic` | Data validation and settings |
| `pyyaml` | Configuration file parsing |

## ğŸ“„ License

See LICENSE file for details.

## ğŸ™ Acknowledgments

Based on MLDT (Multi-Level Decomposition Task) planning architecture with supervised interaction capabilities.
